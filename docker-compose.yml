networks:

  capinet:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 10.5.0.0/16

services:

  # activemq:
  #   container_name: capillaries_activemq
  #   image: apache/activemq-artemis:latest-alpine
  #   depends_on:
  #     - fluentd
  #   networks:
  #     capinet:
  #       ipv4_address: 10.5.0.5
  #   ports:
  #     - 8161:8161 # admin console
  #     - 5672:5672 # amqp port
  #   post_start: # Requires modern version of compose, use sudo apt-get install docker-compose-plugin
  #     - command: sleep 5 # Let it start
  #     # While ActiveMQ also supports dead letter queue (https://activemq.apache.org/components/classic/documentation/message-redelivery-and-dlq-handling)
  #     # it seems to meet our simple needs with just redelivery-delay setting. If, for some reason, it stops working, set up the DLQ.
  #     - command: sed -i -e 's~<redelivery-delay>[0-9]*</redelivery-delay>~<redelivery-delay>5000</redelivery-delay>~g' /var/lib/artemis-instance/etc/broker.xml # 1000 is aggressive, 5000 is reasonable
  #     - command: sed -i -e 's~<address-setting match="#">\n~<address-setting match="#"><management-message-attribute-size-limit>1024</management-message-attribute-size-limit>~g' /var/lib/artemis-instance/etc/broker.xml # Easier troubleshooting
  #     - command: /opt/activemq-artemis/bin/artemis queue create --name capillaries --address capillaries --auto-create-address --anycast --user artemis --password artemis --no-durable --preserve-on-no-consumers # This is THE queue
  #   logging:
  #     driver: fluentd
  #     options:
  #       fluentd-address: 10.5.0.7:24224
  #       fluentd-async: "true"
  #       tag: activemq

  # rabbitmq:
  #   container_name: capillaries_rabbitmq
  #   image: rabbitmq:4-management
  #   depends_on:
  #     - fluentd
  #   networks:
  #     capinet:
  #       ipv4_address: 10.5.0.5
  #   ports:
  #     - 15672:15672
  #     - 5672:5672
  #   post_start:
  #     - command: sleep 5 # Wait a bit before even running rabbitmqctl to avoid some obscure erlang cookie error
  #     - command: rabbitmqctl wait --pid 1 --timeout 60 # With Docker, the pid of main process is always 1
  #     - command: rabbitmqctl set_permissions -p / guest ".*" ".*" ".*" # Set permissions for vhost /
  #     # The following commands set up RabbitMQ dead letter queue infrastructure (no ActiveMQ-style redelivery-delay shortcut in RabbitMQ). Very fragile.
  #     # The only paramater you may want to play with is x-message-ttl.
  #     # Please note that this setup assumes that Capillaries Amqp10.address setting is set to "/queues/capidaemon" 
  #     # Some AMQP 1.0 details (like, why "/queues/capidaemon" and not just "my_simple_capillaries_queue") at https://www.rabbitmq.com/docs/amqp
  #     # Dead letter exchange circle of life explained at https://www.cloudamqp.com/blog/when-and-how-to-use-the-rabbitmq-dead-letter-exchange.html
  #     - command: rabbitmqadmin declare exchange --vhost=/ name=capillaries type=direct durable=false
  #     - command: rabbitmqadmin declare exchange --vhost=/ name=capillaries.dlx type=direct durable=false
  #     - command: rabbitmqadmin declare queue --vhost=/ name=capidaemon durable=false arguments='{"x-dead-letter-exchange":"capillaries.dlx", "x-dead-letter-routing-key":"capidaemon.dlq"}'
  #     - command: rabbitmqadmin declare queue --vhost=/ name=capidaemon.dlq durable=false arguments='{"x-message-ttl":5000, "x-dead-letter-exchange":"capillaries", "x-dead-letter-routing-key":"capidaemon"}'
  #     - command: rabbitmqadmin --vhost=/ declare binding source="capillaries" destination_type="queue" destination="capidaemon" routing_key="capidaemon"
  #     - command: rabbitmqadmin --vhost=/ declare binding source="capillaries.dlx" destination_type="queue" destination="capidaemon.dlq" routing_key="capidaemon.dlq"
  #   logging:
  #     driver: fluentd
  #     options:
  #       fluentd-address: 10.5.0.7:24224
  #       fluentd-async: "true"
  #       tag: rabbitmq

  mq:
    container_name: capillaries_mq
    depends_on:
      - fluentd
    build:
      context: .
      dockerfile: ./pkg/exe/mq/docker/Dockerfile
    environment:
      CAPI_CAPIMQ_BROKER_PORT: 7654
      CAPI_CAPIMQ_BROKER_ACCESS_CONTROL_ALLOW_ORIGIN: webapi_is_the_only_caller_and_it_doesnt_care
      CAPI_CAPIMQ_BROKER_RETURNED_DELIVERY_DELAY: 500
      CAPI_CAPIMQ_BROKER_DEAD_AFTER_NO_HEARTBEAT_TIMEOUT: 10000
      CAPI_LOG_LEVEL: info
    ports:
      - 7654:7654      
    networks:
      capinet:
        ipv4_address: 10.5.0.5
    logging:
      driver: fluentd
      options:
        fluentd-address: 10.5.0.7:24224
        fluentd-async: "true"
        tag: capimq

  cassandra1:
    container_name: capillaries_cassandra1
    build:
      context: .
      dockerfile: ./test/docker/cassandra/Dockerfile
    depends_on:
      - fluentd
    networks:
      capinet:
        ipv4_address: 10.5.0.11
    ports: # Map to known host ports so webapi,toolbelt,daemon running on the host machine can use this Cassandra node
      - 7000:7000
      - 7199:7199
      - 9042:9042
      - 7070:7070
    environment:
      CASSANDRA_SEEDS: 10.5.0.11
    logging:
      driver: fluentd
      options:
        fluentd-address: 10.5.0.7:24224
        fluentd-async: "true"
        tag: cassandra

  # Two cassandras bring my laptop to its knees, make it one 
  # cassandra2:
  #   container_name: capillaries_cassandra2
  #   build:
  #     context: .
  #     dockerfile: ./test/docker/cassandra/Dockerfile
  #   depends_on:
  #     - fluentd
  #   networks:
  #     capinet:
  #       ipv4_address: 10.5.0.12
  #   ports: # Map to different host ports to avoid collision
  #     - 17000:7000
  #     - 17199:7199
  #     - 19042:9042
  #     - 17070:7070
  #   environment:
  #     CASSANDRA_SEEDS: 10.5.0.11
  #   logging:
  #     driver: fluentd
  #     options:
  #       fluentd-address: 10.5.0.7:24224
  #       fluentd-async: "true"
  #       tag: cassandra

  prometheus:
    container_name: capillaries_prometheus
    image: prom/prometheus
    depends_on:
      - fluentd
    networks:
      capinet:
        ipv4_address: 10.5.0.4
    ports:
      - 9090:9090
    volumes:
      - ./test/docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    logging:
      driver: fluentd
      options:
        fluentd-address: 10.5.0.7:24224
        fluentd-async: "true"
        tag: prometheus

  daemon1:
    container_name: capillaries_daemon1
    depends_on:
      - fluentd
    build:
      context: .
      dockerfile: ./pkg/exe/daemon/docker/Dockerfile
    volumes:
      - /tmp/capi_cfg:/tmp/capi_cfg:ro
      - /tmp/capi_in:/tmp/capi_in:ro
      - /tmp/capi_out:/tmp/capi_out
    environment:
      #CAPI_AMQP10_URL: amqp://artemis:artemis@10.5.0.5:5672/
      CAPI_CAPIMQ_CLIENT_URL: http://10.5.0.5:7654
      CAPI_CASSANDRA_HOSTS: 10.5.0.11
      CAPI_CASSANDRA_WRITER_WORKERS: 4
      CAPI_PYCALC_INTERPRETER_PATH: python3
      CAPI_PROMETHEUS_EXPORTER_PORT: 9201
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
    networks:
      capinet:
        ipv4_address: 10.5.0.101
    logging:
      driver: "fluentd"
      options:
        fluentd-address: 10.5.0.7:24224
        fluentd-async: "true"
        tag: daemon

  daemon2:
    container_name: capillaries_daemon2
    depends_on:
      - fluentd
    build:
      context: .
      dockerfile: ./pkg/exe/daemon/docker/Dockerfile
    volumes:
      - /tmp/capi_cfg:/tmp/capi_cfg:ro
      - /tmp/capi_in:/tmp/capi_in:ro
      - /tmp/capi_out:/tmp/capi_out
    environment:
      #CAPI_AMQP10_URL: amqp://artemis:artemis@10.5.0.5:5672/
      CAPI_CAPIMQ_CLIENT_URL: http://10.5.0.5:7654
      CAPI_CASSANDRA_HOSTS: 10.5.0.11
      CAPI_CASSANDRA_WRITER_WORKERS: 4
      CAPI_PROMETHEUS_EXPORTER_PORT: 9202
      CAPI_PYCALC_INTERPRETER_PATH: python3
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
    networks:
      capinet:
        ipv4_address: 10.5.0.102
    logging:
      driver: "fluentd"
      options:
        fluentd-address: 10.5.0.7:24224
        fluentd-async: "true"
        tag: daemon

  webapi:
    container_name: capillaries_webapi
    depends_on:
      - fluentd
    build:
      context: .
      dockerfile: ./pkg/exe/webapi/docker/Dockerfile
    volumes:
      - /tmp/capi_cfg:/tmp/capi_cfg:ro
      - /tmp/capi_in:/tmp/capi_in:ro
      - /tmp/capi_out:/tmp/capi_out
    environment:
      #CAPI_AMQP10_URL: amqp://artemis:artemis@10.5.0.5:5672/
      CAPI_CAPIMQ_CLIENT_URL: http://10.5.0.5:7654
      CAPI_CASSANDRA_HOSTS: 10.5.0.11
      CAPI_WEBAPI_PORT: 6543
      CAPI_WEBAPI_ACCESS_CONTROL_ALLOW_ORIGIN: http://localhost:8080,http://127.0.0.1:8080
      CAPI_PROMETHEUS_EXPORTER_PORT: 9200
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
      CAPI_LOG_LEVEL: info
    ports:
      - 6543:6543      
    networks:
      capinet:
        ipv4_address: 10.5.0.20
    logging:
      driver: fluentd
      options:
        fluentd-address: 10.5.0.7:24224
        fluentd-async: "true"
        tag: webapi
    
  ui:
    container_name: capillaries_ui
    depends_on:
      - fluentd
    build:
      context: .
      dockerfile: ./ui/docker/Dockerfile
    environment:
      CAPI_WEBAPI_URL: http://localhost:6543 # The browser comes there from the outside, so use localhost, not 10.5.0.20
    ports:
      - 8080:8080
    networks:
      capinet:
        ipv4_address: 10.5.0.30
    logging:
      driver: fluentd
      options:
        fluentd-address: 10.5.0.7:24224
        fluentd-async: "true"
        tag: ui

  fluentd:
    container_name: capillaries_fluentd
    build:
      context: .
      dockerfile: ./test/docker/fluentd/Dockerfile
    volumes:
      - /tmp/capi_log:/fluentd/log # Make sure everyone can write there
    ports:
      - 24224:24224
      - 24224:24224/udp
    networks:
      capinet:
        ipv4_address: 10.5.0.7

# Stop all containers
# docker stop $(docker ps -a -q)
# Stop Capillaries binaries containers
# docker stop $(docker ps -a | grep -e daemon -e webapi | awk '{print $1}')
# Delete Capillaries binaries containers
# docker rm $(docker ps -a | grep -e daemon -e webapi | awk '{print $1}')
# Delete all containers
# docker rm $(docker ps -qa)
# Delete Capillaries binaries images
# docker image rm $(docker images | grep -e daemon -e webapi | awk '{print $3}')
# Delete all images
# docker image rm $(docker images | awk '{print $3}')

# Shell to Cassandra:
# docker exec -it $(docker container ls | grep cassandra | awk '{print $1}') bash

# Build one image
# docker compose -p "test_capillaries_containers" build cassandra1

# curl -s -w "\n" -d '{"script_url":"/tmp/capi_cfg/lookup_quicktest/script_quick.yaml", "script_params_url":"/tmp/capi_cfg/lookup_quicktest/script_params_quick_fs_one.yaml", "start_nodes":"read_orders,read_order_items"}' -H "Content-Type: application/json" -X POST "http://localhost:6543/ks/testks1/run"
# /opt/activemq-artemis/bin/artemis queue create --name capillaries --address capillaries --auto-create-address --anycast --user artemis --password artemis --no-durable --preserve-on-no-consumers
# /opt/activemq-artemis/bin/artemis queue delete --name capillaries --user artemis --password artemis
# sed -i -e "s~<redelivery-delay>[0-9]+</redelivery-delay>~<redelivery-delay>5000</redelivery-delay>~2" /var/lib/artemis-instance/etc/broker.xml